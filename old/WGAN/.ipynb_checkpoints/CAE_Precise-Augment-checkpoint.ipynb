{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "import os\n",
    "#os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "\n",
    "from keras.layers import Input, Dense, Reshape, Flatten, Dropout\n",
    "from keras.layers import BatchNormalization, Activation, ZeroPadding2D\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "#from keras.layers.convolutional import UpSampling2D, Conv2D,Conv2DTranspose\n",
    "from keras.layers.convolutional import Conv2D,Conv2DTranspose\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import RMSprop, Adam\n",
    "from keras.initializers import RandomNormal\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import keras.backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import numpy as np\n",
    "from keras.utils import multi_gpu_model\n",
    "import zipfile\n",
    "import glob\n",
    "import shutil as sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rescaleimage(image):\n",
    "    image=(image-127.5)/127.5\n",
    "    return image\n",
    "def reverseimage(image):\n",
    "    image=(image/2)+0.5\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if not os.path.exists('/home/cc/Data/Images'):\n",
    "    os.makedirs('/home/cc/Data/Images')\n",
    "    \n",
    "for p in range(1,6):\n",
    "    zip_ref = zipfile.ZipFile('/home/cc/Data/Section_'+str(p)+'.zip', 'r')\n",
    "    if not os.path.exists('/home/cc/Data/Images/Section_'+str(p)):\n",
    "        os.makedirs('/home/cc/Data/Images/Section_'+str(p))\n",
    "    zip_ref.extractall('/home/cc/Data/Images/Section_'+str(p))\n",
    "    print('part_'+'_'+str(p)+'is extracted')\n",
    "\n",
    "for p in range(1,7):\n",
    "    zip_ref = zipfile.ZipFile('/home/cc/Data/Resized_IARPA_Crossmatch_'+str(p)+'.zip', 'r')\n",
    "    if not os.path.exists('/home/cc/Data/Images/Resized_IARPA_Crossmatch_'+str(p)):\n",
    "        os.makedirs('/home/cc/Data/Images/Resized_IARPA_Crossmatch_'+str(p))\n",
    "    zip_ref.extractall('/home/cc/Data/Images/Resized_IARPA_Crossmatch_'+str(p))\n",
    "    print('part_'+'_'+str(p)+'is extracted')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F = ['Crossmatch Guardian 10 - June 2017.zip', 'Crossmatch Guardian 11 - July 2017.zip', 'Crossmatch Guardian 12 - Sep 2017.zip', \n",
    "     'Crossmatch Guardian 13 - Nov 2017.zip', 'Crossmatch Guardian 3 - May 2015.zip', 'Crossmatch Guardian 4 - Jul 2015.zip', \n",
    "     'Crossmatch Guardian 5 - Sep 2015.zip', 'Crossmatch Guardian 6 - Mar 2016.zip', 'Crossmatch Guardian 7 - Sep 2016.zip', \n",
    "     'Crossmatch Guardian 8 - Dec 2016.zip', 'Crossmatch Guardian 9 - Mar 2017.zip']\n",
    "\n",
    "if not os.path.exists('/home/cc/Data/Images/Precise Dataset'):\n",
    "    os.makedirs('/home/cc/Data/Images/Precise Dataset')\n",
    "for f in range(0, len(F)):\n",
    "    zip_ref = zipfile.ZipFile('/home/cc/Data/'+F[f], 'r')\n",
    "    zip_ref.extractall('/home/cc/Data/Images/Precise Dataset')\n",
    "    print(F[f]+'   is extracted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''putting everything in one folder for augmentaition'''\n",
    "allinone = '/home/cc/Data/allinone/Images2'\n",
    "if not os.path.exists(allinone):\n",
    "    os.makedirs(allinone)\n",
    "\n",
    "files = glob.glob('/home/cc/Data/Images/**/*.bmp', recursive=True)\n",
    "files2 = glob.glob('/home/cc/Data/Images/**/*.png', recursive=True)\n",
    "filesall = files+files2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in filesall:\n",
    "    loc = file.split('/')\n",
    "    dst = allinone+'/'+loc[-1]\n",
    "    sh.copy(file, dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this file had errors\n",
    "#os.remove('('/home/cc/Data/Images2/200318113106_NM1_20150727113416_06_enhanced.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 353178 image(s) found.\n",
      "Output directory set to /home/cc/Data/allinone/Images2/output."
     ]
    }
   ],
   "source": [
    "p = Augmentor.Pipeline(allinone)\n",
    "\n",
    "p.rotate90(probability=0.3)\n",
    "p.rotate270(probability=0.3)\n",
    "p.flip_left_right(probability=0.8)\n",
    "p.flip_top_bottom(probability=0.3)\n",
    "p.crop_random(probability=0.5, percentage_area=0.7)\n",
    "p.resize(probability=1.0, width=512, height=512)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 353178 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "inputTrain ='/home/cc/Data/allinone'\n",
    "img_rows = 512\n",
    "img_cols = 512\n",
    "channels = 3 # I am using channel last models\n",
    "img_shape = (img_rows, img_cols, channels)\n",
    "latent_dim = 512\n",
    "Ngpus=2\n",
    "batch_size=64*Ngpus\n",
    "\n",
    "Imsize=(img_cols,img_cols) # inception requirement\n",
    "datagen=ImageDataGenerator(preprocessing_function=p.keras_preprocess_func())\n",
    "                          \n",
    "image_generator=datagen.flow_from_directory(\n",
    "    inputTrain,\n",
    "    color_mode='rgb',\n",
    "    batch_size= batch_size,\n",
    "    target_size=(img_rows,img_cols),\n",
    "    class_mode='input',\n",
    "    shuffle=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initialize=RandomNormal(mean=0.0, stddev=0.02, seed=None)\n",
    "from keras.regularizers import l2\n",
    "'''\n",
    "G_ENC\n",
    "'''\n",
    "CAE = Sequential()\n",
    "CAE.add(Conv2D(16, kernel_size=4, strides=2, kernel_regularizer=l2(0.0005), kernel_initializer=initialize, input_shape=(512,512,3), padding=\"same\"))\n",
    "CAE.add(BatchNormalization(momentum=0.8))\n",
    "CAE.add(LeakyReLU(alpha=0.2))\n",
    "\n",
    "CAE.add(Conv2D(32, kernel_size=4, strides=2, kernel_regularizer=l2(0.0005), kernel_initializer=initialize, padding=\"same\"))\n",
    "CAE.add(BatchNormalization(momentum=0.8))\n",
    "CAE.add(LeakyReLU(alpha=0.2))\n",
    "\n",
    "CAE.add(Conv2D(64, kernel_size=4, strides=2, kernel_regularizer=l2(0.0005), kernel_initializer=initialize, padding=\"same\"))\n",
    "CAE.add(BatchNormalization(momentum=0.8))\n",
    "CAE.add(LeakyReLU(alpha=0.2))\n",
    "\n",
    "CAE.add(Conv2D(128, kernel_size=4, strides=2, kernel_regularizer=l2(0.0005), kernel_initializer=initialize, padding=\"same\"))\n",
    "CAE.add(BatchNormalization(momentum=0.8))\n",
    "CAE.add(LeakyReLU(alpha=0.2))\n",
    "\n",
    "CAE.add(Conv2D(256, kernel_size=4, strides=2, kernel_regularizer=l2(0.0005), kernel_initializer=initialize, padding=\"same\"))\n",
    "CAE.add(BatchNormalization(momentum=0.8))\n",
    "CAE.add(LeakyReLU(alpha=0.2))\n",
    "\n",
    "CAE.add(Conv2D(512, kernel_size=4, strides=2, kernel_regularizer=l2(0.0005), kernel_initializer=initialize, padding=\"same\"))\n",
    "CAE.add(BatchNormalization(momentum=0.8))\n",
    "CAE.add(LeakyReLU(alpha=0.2))\n",
    "\n",
    "CAE.add(Conv2D(1024, kernel_size=4, strides=2, kernel_regularizer=l2(0.0005), kernel_initializer=initialize, padding=\"same\"))\n",
    "CAE.add(BatchNormalization(momentum=0.8))\n",
    "CAE.add(LeakyReLU(alpha=0.2))\n",
    "\n",
    "CAE.add(Flatten())\n",
    "CAE.add(Dense(512))\n",
    "CAE.add(BatchNormalization(momentum=0.8))\n",
    "CAE.add(LeakyReLU(alpha=0.2))\n",
    "\n",
    "'''\n",
    "G-DEC\n",
    "'''\n",
    "\n",
    "CAE.add(Dense(1024 * 4 * 4))\n",
    "CAE.add(BatchNormalization(momentum=0.8))\n",
    "CAE.add(Activation('relu'))\n",
    "CAE.add(Reshape((4, 4, 1024)))\n",
    "CAE.add(Conv2DTranspose(512, kernel_size=4, strides=2, kernel_regularizer=l2(0.0005), kernel_initializer=initialize, padding=\"same\"))\n",
    "CAE.add(BatchNormalization(momentum=0.8))\n",
    "CAE.add(Activation('relu'))        \n",
    "CAE.add(Conv2DTranspose(256, kernel_size=4, strides=2, kernel_regularizer=l2(0.0005), kernel_initializer=initialize, padding=\"same\"))\n",
    "CAE.add(BatchNormalization(momentum=0.8))\n",
    "CAE.add(Activation('relu'))\n",
    "CAE.add(Conv2DTranspose(128, kernel_size=4, strides=2, kernel_regularizer=l2(0.0005), kernel_initializer=initialize, padding=\"same\"))\n",
    "CAE.add(BatchNormalization(momentum=0.8))\n",
    "CAE.add(Activation('relu'))        \n",
    "CAE.add(Conv2DTranspose(64, kernel_size=4, strides=2, kernel_regularizer=l2(0.0005), kernel_initializer=initialize, padding=\"same\"))\n",
    "CAE.add(BatchNormalization(momentum=0.8))\n",
    "CAE.add(Activation('relu'))\n",
    "CAE.add(Conv2DTranspose(32, kernel_size=4, strides=2, kernel_regularizer=l2(0.0005), kernel_initializer=initialize, padding=\"same\"))\n",
    "CAE.add(BatchNormalization(momentum=0.8))\n",
    "CAE.add(Activation('relu'))\n",
    "CAE.add(Conv2DTranspose(16, kernel_size=4, strides=2, kernel_regularizer=l2(0.0005), kernel_initializer=initialize, padding=\"same\"))\n",
    "CAE.add(BatchNormalization(momentum=0.8))\n",
    "CAE.add(Activation('relu'))\n",
    "CAE.add(Conv2DTranspose(3, kernel_size=4, strides=2, kernel_regularizer=l2(0.0005), kernel_initializer=initialize, padding=\"same\"))\n",
    "CAE.add(BatchNormalization(momentum=0.8))\n",
    "CAE.add(Activation('tanh'))\n",
    "\n",
    "parallel_model = multi_gpu_model(CAE, gpus=Ngpus, cpu_relocation=False)\n",
    "optimizer=Adam(lr=0.0001, beta_1=0.5, beta_2=0.999, epsilon=None, decay=0.0001, amsgrad=True)\n",
    "parallel_model.compile(loss='mse', optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "#CAE = load_model('/home/cc/Data/Model_CAE_v3_final3')\n",
    "#parallel_model = multi_gpu_model(CAE, gpus=Ngpus, cpu_relocation=False)\n",
    "#optimizer=Adam(lr=0.00001, beta_1=0.5, beta_2=0.999, epsilon=None, decay=0.001, amsgrad=True)\n",
    "#parallel_model.compile(loss='mse', optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import TensorBoard, ModelCheckpoint\n",
    "TS = TensorBoard(log_dir='/home/cc/Data/Tests/logs', histogram_freq=0, batch_size=batch_size)\n",
    "MC = ModelCheckpoint(os.path.join('/home/cc/Data/Tests','MC'), \n",
    "                        monitor='loss', verbose=0, save_best_only=True, \n",
    "                        save_weights_only=True, mode='auto', period=1)\n",
    "\n",
    "parallel_model.fit_generator(g, steps_per_epoch=len(p.augmentor_images)/batch_size, epochs=100, \n",
    "                             verbose=1, max_queue_size=30, workers=6, use_multiprocessing=True, callbacks=[TS, MC])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CAE.save('/home/cc/Data/Model_CAE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = image_generator.next()[0]\n",
    "x = CAE.predict(x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = []\n",
    "img2 = []\n",
    "N = [0,1,2, 3, 4, 5,]\n",
    "for n in N:\n",
    "    img1.append(x1[n,:,:,:])\n",
    "    img2.append(x[n,:,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in N:\n",
    "    img1[n] = img1[n]/2\n",
    "    img1[n] = img1[n]+0.5\n",
    "    img2[n] = img2[n]/2\n",
    "    img2[n] = img2[n]+0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "i=1\n",
    "plt.figure(figsize=(10, 10))\n",
    "for n in N:\n",
    "    plt.subplot(6,2,i)\n",
    "    plt.imshow(img1[n])\n",
    "    i= i+1\n",
    "    plt.subplot(6,2,i)\n",
    "    plt.imshow(img2[n])\n",
    "    i=i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(img2[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

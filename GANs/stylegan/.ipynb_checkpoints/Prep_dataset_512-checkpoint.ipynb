{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import sys\n",
    "'''PATH to lpips library for perceptual loss'''\n",
    "new_path = '/home/cc/stylegan_K1/'\n",
    "sys.path.append(new_path)\n",
    "\n",
    "import glob\n",
    "import argparse\n",
    "import threading\n",
    "import six.moves.queue as Queue # pylint: disable=import-error\n",
    "import traceback\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import PIL.Image\n",
    "import dnnlib.tflib as tflib\n",
    "\n",
    "from training import dataset\n",
    "import pandas as pd\n",
    "import shutil as sh\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from skimage.transform import resize\n",
    "from skimage import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TFRecordExporter:\n",
    "    def __init__(self, tfrecord_dir, expected_images, print_progress=True, progress_interval=10):\n",
    "        self.tfrecord_dir       = tfrecord_dir\n",
    "        self.tfr_prefix         = os.path.join(self.tfrecord_dir, os.path.basename(self.tfrecord_dir))\n",
    "        self.expected_images    = expected_images\n",
    "        self.cur_images         = 0\n",
    "        self.shape              = None\n",
    "        self.resolution_log2    = None\n",
    "        self.tfr_writers        = []\n",
    "        self.print_progress     = print_progress\n",
    "        self.progress_interval  = progress_interval\n",
    "\n",
    "        if self.print_progress:\n",
    "            print('Creating dataset \"%s\"' % tfrecord_dir)\n",
    "        if not os.path.isdir(self.tfrecord_dir):\n",
    "            os.makedirs(self.tfrecord_dir)\n",
    "        assert os.path.isdir(self.tfrecord_dir)\n",
    "\n",
    "    def close(self):\n",
    "        if self.print_progress:\n",
    "            print('%-40s\\r' % 'Flushing data...', end='', flush=True)\n",
    "        for tfr_writer in self.tfr_writers:\n",
    "            tfr_writer.close()\n",
    "        self.tfr_writers = []\n",
    "        if self.print_progress:\n",
    "            print('%-40s\\r' % '', end='', flush=True)\n",
    "            print('Added %d images.' % self.cur_images)\n",
    "\n",
    "    def choose_shuffled_order(self): # Note: Images and labels must be added in shuffled order.\n",
    "        order = np.arange(self.expected_images)\n",
    "        np.random.RandomState(123).shuffle(order)\n",
    "        return order\n",
    "\n",
    "    def add_image(self, img):\n",
    "        if self.print_progress and self.cur_images % self.progress_interval == 0:\n",
    "            print('%d / %d\\r' % (self.cur_images, self.expected_images), end='', flush=True)\n",
    "        if self.shape is None:\n",
    "            self.shape = img.shape\n",
    "            self.resolution_log2 = int(np.log2(self.shape[1]))\n",
    "            assert self.shape[0] in [1, 3]\n",
    "            assert self.shape[1] == self.shape[2]\n",
    "            assert self.shape[1] == 2**self.resolution_log2\n",
    "            tfr_opt = tf.python_io.TFRecordOptions(tf.python_io.TFRecordCompressionType.NONE)\n",
    "            for lod in range(self.resolution_log2 - 1):\n",
    "                tfr_file = self.tfr_prefix + '-r%02d.tfrecords' % (self.resolution_log2 - lod)\n",
    "                self.tfr_writers.append(tf.python_io.TFRecordWriter(tfr_file, tfr_opt))\n",
    "        assert img.shape == self.shape\n",
    "        for lod, tfr_writer in enumerate(self.tfr_writers):\n",
    "            if lod:\n",
    "                img = img.astype(np.float32)\n",
    "                img = (img[:, 0::2, 0::2] + img[:, 0::2, 1::2] + img[:, 1::2, 0::2] + img[:, 1::2, 1::2]) * 0.25\n",
    "            quant = np.rint(img).clip(0, 255).astype(np.uint8)\n",
    "            ex = tf.train.Example(features=tf.train.Features(feature={\n",
    "                'shape': tf.train.Feature(int64_list=tf.train.Int64List(value=quant.shape)),\n",
    "                'data': tf.train.Feature(bytes_list=tf.train.BytesList(value=[quant.tostring()]))}))\n",
    "            tfr_writer.write(ex.SerializeToString())\n",
    "        self.cur_images += 1\n",
    "\n",
    "    def add_labels(self, labels):\n",
    "        if self.print_progress:\n",
    "            print('%-40s\\r' % 'Saving labels...', end='', flush=True)\n",
    "        assert labels.shape[0] == self.cur_images\n",
    "        with open(self.tfr_prefix + '-rxx.labels', 'wb') as f:\n",
    "            np.save(f, labels.astype(np.float32))\n",
    "\n",
    "    def __enter__(self):\n",
    "        return self\n",
    "\n",
    "    def __exit__(self, *args):\n",
    "        self.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Putting all the live samples in one folder for TF record'''\n",
    "data_pd = pd.read_pickle('/home/cc/Data/Zips/cm_index_df_fixed.p')\n",
    "data_pd['FilePath']= data_pd.FilePath.apply(lambda x: os.path.join('/home/cc/Data/Images',x))\n",
    "data_live = data_pd[data_pd.live_spoof == 0] # only live samples\n",
    "data_live['Collection'] = data_live.CaptureID.apply(lambda x: x[0:3])\n",
    "resize_df = data_live[data_live.Collection =='Pre']\n",
    "resize_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resize_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_subjects = sorted(resize_df.SubjectID.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Selecting 500 subjects'''\n",
    "train_subject = unique_subjects[0:250]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_df = pd.DataFrame()\n",
    "for subject in train_subject:\n",
    "    sub_df = resize_df[resize_df.SubjectID== subject]\n",
    "    Train_df = pd.concat([Train_df,sub_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_loc = '/home/cc/Data/Allinone'\n",
    "if not os.path.exists(images_loc):\n",
    "    os.mkdir(images_loc)\n",
    "image_rgb = np.zeros((512,512,3), dtype=np.uint8)\n",
    "for i in range(len(Train_df)):    \n",
    "    splits = resize_df.iloc[i,3].split('/')\n",
    "    '''Gray to RGB for style loss we have to do this'''\n",
    "    img = io.imread(Train_df.iloc[i,3])\n",
    "    image_pad = np.pad(img, (56, 56), 'constant', constant_values=(255))\n",
    "    image_rgb[:,:,0] = image_pad\n",
    "    image_rgb[:,:,1] = image_pad\n",
    "    image_rgb[:,:,2] = image_pad\n",
    "    io.imsave(os.path.join(images_loc,splits[-1]), image_rgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Cleaning the dataset - We have messed up images!!!!'''\n",
    "image_filenames = sorted(glob.glob(os.path.join(images_loc, '*')))\n",
    "Errors_channel = []\n",
    "Errors_resulution = []\n",
    "cleaned_filenames = []\n",
    "for i in image_filenames:\n",
    "    img = np.asarray(PIL.Image.open(i))\n",
    "    if img.shape[2] !=3: \n",
    "        Errors_channel.append(i)\n",
    "    elif img.shape[1] != 512:\n",
    "        Errors_resulution.append(i)\n",
    "    else:\n",
    "        cleaned_filenames.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(image_filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(cleaned_filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Errors_channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Errors_resulution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_from_images(tfrecord_dir, image_dir, shuffle):\n",
    "    print('Loading images from \"%s\"' % image_dir)\n",
    "    image_filenames = sorted(glob.glob(os.path.join(image_dir, '*')))\n",
    "    if len(image_filenames) == 0:\n",
    "        error('No input images found')\n",
    "\n",
    "    img = np.asarray(PIL.Image.open(image_filenames[0]))\n",
    "    resolution = img.shape[0]\n",
    "    channels = img.shape[2] if img.ndim == 3 else 1\n",
    "    if img.shape[1] != resolution:\n",
    "        error('Input images must have the same width and height')\n",
    "    if resolution != 2 ** int(np.floor(np.log2(resolution))):\n",
    "        error('Input image resolution must be a power-of-two')\n",
    "    if channels not in [1, 3]:\n",
    "        error('Input images must be stored as RGB or grayscale')\n",
    "    \n",
    "    with TFRecordExporter(tfrecord_dir, len(image_filenames)) as tfr:\n",
    "        order = tfr.choose_shuffled_order() if shuffle else np.arange(len(image_filenames))\n",
    "        for idx in range(order.size):\n",
    "            img = np.asarray(PIL.Image.open(image_filenames[order[idx]]))\n",
    "            if channels == 1:\n",
    "                img = img[np.newaxis, :, :] # HW => CHW\n",
    "            else:\n",
    "                img = img.transpose([2, 0, 1]) # HWC => CHW\n",
    "            tfr.add_image(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('/home/cc/Data/Finger_512'):\n",
    "    os.mkdir('/home/cc/Data/Finger')\n",
    "\n",
    "create_from_images('/home/cc/Data/Finger_512', images_loc , False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
